# ü§ñ GitHub Models - Supported Models for OCR

## ‚úÖ Tested & Working Models

### **OpenAI Vision Models**

| Model | Status | Vision Support | Rate Limit | Accuracy | Speed | Recommended |
|-------|--------|----------------|------------|----------|-------|-------------|
| **gpt-4o** | ‚úÖ Working | ‚úÖ Yes | ~50 req/day | 90-95% | Medium | ‚≠ê Best |
| **gpt-4o-mini** | ‚úÖ Working | ‚úÖ Yes | ~50+ req/day | 85-90% | Fast | ‚≠ê Fastest |

---

## ‚ùå NOT Supported Models

### **Microsoft Models**
| Model | Status | Reason |
|-------|--------|--------|
| ‚ùå Phi-4 | Not Working | Error: "Unknown image model type: phi3" |
| ‚ùå Phi-3-vision-128k-instruct | Not Working | Error: "Unknown model" |
| ‚ùå Phi-3.5-vision-instruct | Not Working | Error: "Unknown model" |

### **OpenAI Reasoning Models**
| Model | Status | Reason |
|-------|--------|--------|
| ‚ùå o1-preview | Not Supported | No vision support (text-only) |
| ‚ùå o1-mini | Not Supported | No vision support (text-only) |

### **Other Models**
| Model | Status | Reason |
|-------|--------|--------|
| ‚ùå Claude-3 (Anthropic) | Unknown | Not tested |
| ‚ùå Llama (Meta) | Unknown | Not tested |

---

## üìã Current Configuration

**File:** `.env.ocr`

```bash
# Recommended: gpt-4o-mini (fastest, good accuracy)
GITHUB_MODELS_MODEL=gpt-4o-mini

# Alternative: gpt-4o (best accuracy, slightly slower)
# GITHUB_MODELS_MODEL=gpt-4o
```

---

## üîÑ How to Change Model

### Option 1: Edit `.env.ocr`
```bash
# Open .env.ocr
GITHUB_MODELS_MODEL=gpt-4o-mini  # Change this line
```

### Option 2: Environment Variable
```powershell
# Windows PowerShell
$env:GITHUB_MODELS_MODEL="gpt-4o"

# Restart your app
npm start
```

---

## üìä Performance Comparison

### **Test Results (CAPTCHA OCR)**

| Model | Avg Time | Success Rate | Rate Limit Hit | Cost |
|-------|----------|--------------|----------------|------|
| gpt-4o | ~2-3s | 92% | After 50 req | Free |
| gpt-4o-mini | ~1-2s | 88% | After 50+ req | Free |
| Tesseract | <1s | 70% | Unlimited | Free |
| PaddleOCR | <1s | 85% | Unlimited | Free |

---

## ‚ö†Ô∏è Known Issues

### 1. **Rate Limiting**
**Error:**
```
‚ùå GitHub Models: Rate limited (too many requests)
‚è∞ Reached rate limit (50 requests/86400s)
```

**Solution:**
- Wait 24 hours
- Or use multi-tier fallback: `OCR_TIER_ORDER=tesseract,github,paddle`

### 2. **Model Not Found**
**Error:**
```
‚ùå GitHub Models error: Request failed with status code 400
{"error":{"code":"unknown_model","message":"Unknown model: phi-4"}}
```

**Solution:**
- Use only supported models: `gpt-4o` or `gpt-4o-mini`
- Check spelling in `.env.ocr`

### 3. **Vision Not Supported**
**Error:**
```
‚ùå GitHub Models error: Request failed with status code 400
{"error":{"message":"Unknown image model type"}}
```

**Solution:**
- Don't use o1-preview, o1-mini (no vision)
- Don't use Phi models (not available on GitHub Models)

---

## üöÄ Quick Start

### 1. Set GitHub Token
```bash
# In .env.ocr
GITHUB_TOKEN=your_github_token_here
```

### 2. Choose Model
```bash
GITHUB_MODELS_MODEL=gpt-4o-mini
```

### 3. Configure Tier Order
```bash
# Default: Tesseract first (safe)
OCR_TIER_ORDER=tesseract,github,paddle

# Or: GitHub Models first (most accurate)
OCR_TIER_ORDER=github,tesseract,paddle
```

### 4. Test
```bash
npm start
```

**Expected Output:**
```
üìã Tier Order: tesseract ‚Üí github ‚Üí paddle
üì¶ Using model: gpt-4o-mini
‚ÑπÔ∏è GPT-4o-mini (OpenAI) - Faster, potentially higher rate limit
‚úÖ GitHub Models SUCCESS: "ABC123"
```

---

## üéØ Recommendations

### **For Production:**
```bash
# Safe configuration with multi-tier fallback
OCR_TIER_ORDER=tesseract,github,paddle
GITHUB_MODELS_MODEL=gpt-4o-mini
```

**Why?**
- ‚úÖ Tesseract handles most cases (unlimited)
- ‚úÖ GitHub Models for difficult cases (50/day)
- ‚úÖ PaddleOCR as last resort (requires setup)

### **For Best Accuracy:**
```bash
# Use GitHub Models first (if you have rate limit headroom)
OCR_TIER_ORDER=github,tesseract,paddle
GITHUB_MODELS_MODEL=gpt-4o
```

**Why?**
- ‚úÖ gpt-4o has highest accuracy (92%)
- ‚úÖ Falls back to Tesseract if rate limited
- ‚ö†Ô∏è Will hit rate limit faster

### **For Speed:**
```bash
# Use local OCR first
OCR_TIER_ORDER=paddle,tesseract,github
GITHUB_MODELS_MODEL=gpt-4o-mini
```

**Why?**
- ‚úÖ PaddleOCR is fastest (if working)
- ‚úÖ No network latency
- ‚ö†Ô∏è Requires VC++ Redistributable

---

## üìö References

- **GitHub Models Docs**: https://github.com/marketplace/models
- **OpenAI Vision API**: https://platform.openai.com/docs/guides/vision
- **Rate Limits**: ~50 requests per 24 hours (subject to change)

---

## ‚úÖ Summary

**Working Models:**
- ‚úÖ `gpt-4o` - Best accuracy
- ‚úÖ `gpt-4o-mini` - Best speed

**NOT Working:**
- ‚ùå All Phi models (Phi-3, Phi-4)
- ‚ùå o1 models (no vision)
- ‚ùå Claude, Llama (not tested/available)

**Recommended Setup:**
```bash
OCR_TIER_ORDER=tesseract,github,paddle
GITHUB_MODELS_MODEL=gpt-4o-mini
```

---

_Last Updated: November 9, 2025_  
_Tested on: GitHub Models API via Azure_
